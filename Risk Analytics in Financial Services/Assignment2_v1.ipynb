{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import os\n",
    "from pathlib import Path\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to change.org-topic and twitter-topic datasets\n",
    "path1 = './change.org_topic'\n",
    "path2 = './twitter_topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating three files for \"lockdowns\", \"masking and distancing\", and \"vaccination\" for each file in the\n",
    "# Change.org Topic Dataset\n",
    "for file in os.listdir(path1):\n",
    "    if file.endswith(\".csv\") and ((\"lockdowns\" not in file) and (\"masking_and_distancing\" not in file) and (\"vaccination\" not in file))  :\n",
    "        full_path = path1 + '/' + file\n",
    "        %run expand_topic_csv_dataset.py --infile $full_path       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating three files for \"lockdowns\", \"masking and distancing\", and \"vaccination\" for each file in the\n",
    "# Twitter Topic Dataset\n",
    "for file in os.listdir(path2):\n",
    "    if file.endswith(\".csv\") and ((\"lockdowns\" not in file) and (\"masking_and_distancing\" not in file) and (\"vaccination\" not in file))  :\n",
    "        full_path = path2 + '/' + file\n",
    "        %run expand_topic_csv_dataset.py --infile $full_path        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./change.org_topic/change.org_topic_0_lockdowns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Column names and number of annotators\n",
    "annotators = list(df.columns[1:])\n",
    "no_of_annotators = len(annotators)\n",
    "      \n",
    "# Generate all the pair of annotators \n",
    "combinations = []\n",
    "for annotator1 in annotators:\n",
    "    for annotator2 in annotators:\n",
    "        if annotator1 != annotator2:\n",
    "            combinations.append((annotator1, annotator2))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('annotation_96', 'annotation_53'),\n",
       " ('annotation_96', 'annotation_93'),\n",
       " ('annotation_96', 'annotation_94'),\n",
       " ('annotation_96', 'annotation_95'),\n",
       " ('annotation_53', 'annotation_96'),\n",
       " ('annotation_53', 'annotation_93'),\n",
       " ('annotation_53', 'annotation_94'),\n",
       " ('annotation_53', 'annotation_95'),\n",
       " ('annotation_93', 'annotation_96'),\n",
       " ('annotation_93', 'annotation_53'),\n",
       " ('annotation_93', 'annotation_94'),\n",
       " ('annotation_93', 'annotation_95'),\n",
       " ('annotation_94', 'annotation_96'),\n",
       " ('annotation_94', 'annotation_53'),\n",
       " ('annotation_94', 'annotation_93'),\n",
       " ('annotation_94', 'annotation_95'),\n",
       " ('annotation_95', 'annotation_96'),\n",
       " ('annotation_95', 'annotation_53'),\n",
       " ('annotation_95', 'annotation_93'),\n",
       " ('annotation_95', 'annotation_94')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator: annotation_96, Score: 0.07163323782234965\n",
      "Annotator: annotation_96, Score: 0.4598199399799934\n",
      "Annotator: annotation_96, Score: 0.48709002093510123\n",
      "Annotator: annotation_96, Score: 0.4885703215807826\n",
      "Annotator: annotation_53, Score: 0.07163323782234965\n",
      "Annotator: annotation_53, Score: -0.03214124038026256\n",
      "Annotator: annotation_53, Score: 0.02791625124626107\n",
      "Annotator: annotation_53, Score: 0.08338637810311889\n",
      "Annotator: annotation_93, Score: 0.4598199399799934\n",
      "Annotator: annotation_93, Score: -0.03214124038026256\n",
      "Annotator: annotation_93, Score: 0.5129249968165033\n",
      "Annotator: annotation_93, Score: 0.44218717719165346\n",
      "Annotator: annotation_94, Score: 0.48709002093510123\n",
      "Annotator: annotation_94, Score: 0.02791625124626107\n",
      "Annotator: annotation_94, Score: 0.5129249968165033\n",
      "Annotator: annotation_94, Score: 0.6851020703633994\n",
      "Annotator: annotation_95, Score: 0.4885703215807826\n",
      "Annotator: annotation_95, Score: 0.08338637810311889\n",
      "Annotator: annotation_95, Score: 0.44218717719165346\n",
      "Annotator: annotation_95, Score: 0.6851020703633994\n"
     ]
    }
   ],
   "source": [
    "# Calculate average Kappa Score for each annotator\n",
    "scores = dict()\n",
    "count = 0\n",
    "score = 0\n",
    "for annotator in annotators:\n",
    "    for combination in combinations:\n",
    "        if combination[0] == annotator:\n",
    "            kappa = cohen_kappa_score(df[combination[0]], df[combination[1]])\n",
    "            print(\"Annotator: {}, Score: {}\".format(annotator,kappa))\n",
    "            score = score + kappa\n",
    "            count = count + 1\n",
    "    scores[annotator] = score/(len(annotators) - 1)        \n",
    "    score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part1(df):\n",
    "    # Converting the datatype of label columns to String.\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    # Replace missing values with Unknown\n",
    "    df = df.fillna(\"Unknown\")\n",
    "    \n",
    "    # Get the Column names and number of annotators\n",
    "    annotators = list(df.columns[1:])\n",
    "    no_of_annotators = len(annotators)\n",
    "      \n",
    "    # Generate all the pair of annotators \n",
    "    combinations = []\n",
    "    for annotator1 in annotators:\n",
    "        for annotator2 in annotators:\n",
    "            if annotator1 != annotator2:\n",
    "                combinations.append((annotator1, annotator2))    \n",
    "        \n",
    "    # Calculate Kappa Score for every combination.\n",
    "    #kk_score = [cohen_kappa_score(df[c[0]], df[c[1]])for c in combinations] \n",
    "    \n",
    "    # Calculate average Kappa Score for each annotator\n",
    "    scores = dict()\n",
    "    count = 0\n",
    "    score = 0\n",
    "    for annotator in annotators:\n",
    "        for combination in combinations:\n",
    "            if combination[0] == annotator:\n",
    "                score = score + cohen_kappa_score(df[combination[0]], df[combination[1]])\n",
    "                count = count + 1\n",
    "        scores[annotator] = score/(len(annotators) - 1)        \n",
    "        score = 0\n",
    "        \n",
    "    # Drop the annotators with average kappa score less than 0.2\n",
    "    for key, value in scores.items():\n",
    "        if value < 0.2:\n",
    "            df = df.drop([key],axis=1)   \n",
    "            \n",
    "    # Get the name of remaining annotators\n",
    "    annotators_final = list(df.columns[1:])\n",
    "    annotators_final  \n",
    "    \n",
    "    return df, scores, annotators_final    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part2(df, scores, annotators_final):\n",
    "    '''\n",
    "       Maintaining three variables True_Count, False_Count, and Unknown_Count to store the count of \"True\", \"False\", and\n",
    "       \"Unknown\" labels in each row.\n",
    "\n",
    "       Also, maintaining three variables True_Kappa, False_Kappa, and Unknown_Kappa to store the average Kappa score for\n",
    "       \"True\", \"False\", and \"Unknown\" label in each row.\n",
    "\n",
    "       If the count of one label is highest the corresponding label is considered. \n",
    "       If the count of two labels are equal and non-zero, the label with highest average Kappa score is considered.\n",
    "    '''\n",
    "    True_Count = 0\n",
    "    False_Count = 0\n",
    "    Unknown_Count = 0\n",
    "    True_Kappa = 0\n",
    "    False_Kappa = 0\n",
    "    Unknown_Kappa = 0\n",
    "    for index, row in df.iterrows():\n",
    "        for annotator in annotators_final:\n",
    "            if row[annotator] == \"True\":\n",
    "                True_Count += 1\n",
    "                True_Kappa += scores[annotator]\n",
    "            if row[annotator] == \"False\":\n",
    "                False_Count += 1\n",
    "                False_Kappa += scores[annotator]\n",
    "            if row[annotator] == \"Unknown\":\n",
    "                Unknown_Count += 1\n",
    "                Unknown_Kappa += scores[annotator]\n",
    "     \n",
    "        # Calculating average Kappa Score for each label\n",
    "        if True_Count != 0:\n",
    "            True_Kappa = True_Kappa / True_Count\n",
    "        if False_Count != 0:\n",
    "            False_Kappa = False_Kappa / False_Count\n",
    "        if Unknown_Count != 0:\n",
    "            Unknown_Kappa = Unknown_Kappa / Unknown_Count\n",
    "\n",
    "        # Checking if any one label has highest count.\n",
    "        if True_Count > False_Count and  True_Count > Unknown_Count:\n",
    "            label = \"True\"\n",
    "        if False_Count > True_Count  and False_Count > Unknown_Count:\n",
    "            label = \"False\"\n",
    "        if Unknown_Count > True_Count  and Unknown_Count > False_Count:  \n",
    "            label = \"Unknown\"\n",
    "    \n",
    "        # Checking if two labels have same count and not equal to 0\n",
    "        if True_Count == False_Count and True_Count != 0:\n",
    "            if True_Kappa > False_Kappa:\n",
    "                label = \"True\"\n",
    "            else:\n",
    "                label = \"False\"\n",
    "    \n",
    "        if True_Count == Unknown_Count and True_Count != 0:\n",
    "            if True_Kappa > Unknown_Kappa:\n",
    "                label = \"True\"\n",
    "            else:\n",
    "                label = \"Unknown\"\n",
    "    \n",
    "        if False_Count == Unknown_Count and False_Count != 0:\n",
    "            if False_Kappa > Unknown_Kappa:\n",
    "                label = \"False\"\n",
    "            else: \n",
    "                label = \"Unknown\"\n",
    "        # Store the label value for each row in a new \"label\" column of the DataFrame.        \n",
    "        df.at[index,'label'] = label\n",
    "    \n",
    "        # Reset the variable for processing the next row.\n",
    "        True_Count = 0\n",
    "        False_Count = 0\n",
    "        Unknown_Count = 0\n",
    "        True_Kappa = 0\n",
    "        False_Kappa = 0\n",
    "        Unknown_Kappa = 0\n",
    "    # Dropping the labels corresponding to different anotators\n",
    "    df = df.drop(annotators_final,axis=1)     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    df, scores, annotators_final = Part1(df)\n",
    "    df = Part2(df, scores, annotators_final)\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Performing execution on every file in change.org dataset and writing the dataset back with same name.\n",
    "for file in os.listdir(path1):\n",
    "    if file.endswith(\".csv\") and ((\"lockdowns\" in file) or (\"masking_and_distancing\" in file) or (\"vaccination\" in file)):\n",
    "        full_path = path1 + '/' + file\n",
    "        execution(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing execution on every file in twitter dataset and writing the dataset back with same name.\n",
    "for file in os.listdir(path2):\n",
    "    if file.endswith(\".csv\") and ((\"lockdowns\" in file) or (\"masking_and_distancing\" in file) or (\"vaccination\" in file)):\n",
    "        full_path = path2 + '/' + file\n",
    "        execution(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################  Output file 1 ###################################\n",
    "# Merging all the files corresponding to lockdowns for change.org\n",
    "frames = []\n",
    "for file in os.listdir(path1):\n",
    "    if file.endswith(\".csv\") and ((\"lockdowns\" in file)) :\n",
    "        full_path = path1 + '/' + file\n",
    "        frames.append(pd.read_csv(full_path))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "file_name = path1 + '/' + \"change.org_topic_lockdowns.csv\"\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################  Output file 2 ###################################\n",
    "# Merging all the files corresponding to masking_and_distancing for change.org\n",
    "frames = []\n",
    "for file in os.listdir(path1):\n",
    "    if file.endswith(\".csv\") and ((\"masking_and_distancing\" in file)) :\n",
    "        full_path = path1 + '/' + file\n",
    "        frames.append(pd.read_csv(full_path))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "file_name = path1 + '/' + \"change.org_topic_masking_and_distancing.csv\"\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################  Output file 3 ###################################\n",
    "# Merging all the files corresponding to vaccination for change.org\n",
    "frames = []\n",
    "for file in os.listdir(path1):\n",
    "    if file.endswith(\".csv\") and ((\"vaccination\" in file)) :\n",
    "        full_path = path1 + '/' + file\n",
    "        frames.append(pd.read_csv(full_path))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "result.head()\n",
    "file_name = path1 + '/' + \"change.org_topic_vaccination.csv\"\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################  Output file 4 ###################################\n",
    "# Merging all the files corresponding to lockdowns for Twitter\n",
    "frames = []\n",
    "for file in os.listdir(path2):\n",
    "    if file.endswith(\".csv\") and ((\"lockdowns\" in file)) :\n",
    "        full_path = path2 + '/' + file\n",
    "        frames.append(pd.read_csv(full_path))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "file_name = path2 + '/' + \"twitter_topic_lockdowns.csv\"\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################  Output file 5 ###################################\n",
    "# Merging all the files corresponding to masking_and_distancing for Twitter\n",
    "frames = []\n",
    "for file in os.listdir(path2):\n",
    "    if file.endswith(\".csv\") and ((\"masking_and_distancing\" in file)) :\n",
    "        full_path = path2 + '/' + file\n",
    "        frames.append(pd.read_csv(full_path))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "file_name = path2 + '/' + \"twitter_topic_masking_and_distancing.csv\"\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################  Output file 4 ###################################\n",
    "# Merging all the files corresponding to vaccination for Twitter\n",
    "frames = []\n",
    "for file in os.listdir(path2):\n",
    "    if file.endswith(\".csv\") and ((\"vaccination\" in file)) :\n",
    "        full_path = path2 + '/' + file\n",
    "        frames.append(pd.read_csv(full_path))\n",
    "\n",
    "result = pd.concat(frames)\n",
    "file_name = path2 + '/' + \"twitter_topic_vaccination.csv\"\n",
    "result.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
